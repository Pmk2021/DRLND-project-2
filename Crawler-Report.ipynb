{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we will see an implementation for an optional part of the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawler\n",
    "\n",
    "We apply the same algorithm to try to solve the Crawler problem -- with a few different hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n",
    "\n",
    "Agent hyperparameters may be passed as constructor arguments to `MultiAgent`.  The default values, used in this workbook, are:\n",
    "\n",
    "| parameter                | value           | description                                                                   |\n",
    "|--------------------------|-----------------|-------------------------------------------------------------------------------|\n",
    "| shared_network_units     | []              | Network topology for shared network between actor and critic functions        |\n",
    "| actor_network_units      | [512, 512, 512] | Network topology for actor network function                                   |\n",
    "| critic_network_units     | [512, 512, 512] | Network topology for critic network function                                  |\n",
    "| optimizer_learning_rate  | 5e-6            | Initial learning rate for Adam optimizer                                      |\n",
    "| optimizer_epsilon        | 1e-5            | Tolerance parameter for Adam optimizer                                        |\n",
    "| weight_decay             | 1e-4            | Weight decay for Adam optimizer                                               |\n",
    "| trajectory_length        | 1000            | Number of steps cached before trajectory rollback                             |\n",
    "| gamma                    | 0.9             | Discount rate for future rewards                                              |\n",
    "| gae_lambda               | 0.95            | Interpolating parameter for GAE                                               |\n",
    "| optimization_steps       | 32              | Number of optimization steps to perform after trajectory rollback             |\n",
    "| batch_size               | 1024            | Number of N-agent experiences to collect for a single optimization step       |\n",
    "| gradient_clip            | 0.25            | Clipping parameter for gradient descent during optimization                   |\n",
    "| ppo_ratio_clip_epsilon   | 0.1             | Clipping parameter for the policy loss function                               |\n",
    "| entropy_penalty_weight   | 0.01            | Weight applied to entropy penalty on total loss function                      |\n",
    "| value_loss_weight        | 1.0             | Weight applied to value loss on total loss function                           |\n",
    "| std_init                 | -2.5            | Initialization parameter for sigma                                            |\n",
    "\n",
    "Training hyperparameters are passed on the training function itself, `train_multiagent`, defined below.  The selected values are:\n",
    "\n",
    "| parameter                     | value     | description                                           |\n",
    "|-------------------------------|-----------|-------------------------------------------------------|\n",
    "| n_episodes                    | 2000      | Maximum number of training episodes                   |\n",
    "| max_t                         | 1000      | Maximum number of steps per episode                   |\n",
    "| solved_score                  | 500       | Average score required to consider problem solved     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def train_multiagent(\n",
    "    env, \n",
    "    multiagent, \n",
    "    n_episodes=300, \n",
    "    max_t=1000, \n",
    "    display_every=10,\n",
    "    solved_score=30, \n",
    "    save_filename=None,\n",
    "    std_scale=None\n",
    "):\n",
    "    scores = []\n",
    "    scores_window = deque(maxlen=100)\n",
    "        \n",
    "    for i_episode in range(1, n_episodes + 1):    \n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        \n",
    "        n_actors = len(env_info.vector_observations)\n",
    "        score = np.zeros(n_actors)\n",
    "\n",
    "        episode_length_list = []\n",
    "        episode_counter = np.zeros(n_actors)\n",
    "        \n",
    "        for t in range(1, max_t+1):\n",
    "            states = env_info.vector_observations\n",
    "            if np.isnan(states).any():\n",
    "                print('\\nNaN found in states')\n",
    "                break\n",
    "            \n",
    "            std_scale_value = 1.0 if std_scale is None else std_scale(i_episode)\n",
    "            \n",
    "            actions = multiagent.act(states, std_scale=std_scale_value)\n",
    "            \n",
    "            if np.isnan(actions).any():\n",
    "                print('\\nNaN found in actions')\n",
    "                return scores\n",
    "            \n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            \n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = np.array(env_info.rewards)\n",
    "            \n",
    "            if np.isnan(rewards).any():\n",
    "                print('\\nNaN found in rewards')\n",
    "                rewards = np.where(np.isnan(rewards), 0, rewards)\n",
    "                \n",
    "            dones = env_info.local_done\n",
    "            \n",
    "            multiagent.step(\n",
    "                states, \n",
    "                actions, \n",
    "                rewards,\n",
    "                next_states, \n",
    "                dones,\n",
    "                std_scale=std_scale_value\n",
    "            )\n",
    "            \n",
    "            score += np.array(rewards)\n",
    "            score = np.where(dones, 0, score)\n",
    "            \n",
    "        mean_score = score.mean()\n",
    "        scores_window.append(mean_score)       # save most recent score\n",
    "        scores.append(mean_score)              # save most recent score\n",
    "        \n",
    "        print('\\rEpisode {}\\tAverage score: {:.2f}'.format(\n",
    "            i_episode, np.mean(scores_window)\n",
    "        ), end=\"\")\n",
    "        if i_episode % display_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage score: {:.2f}'.format(\n",
    "                i_episode, np.mean(scores_window)\n",
    "            ))\n",
    "            \n",
    "        if np.mean(scores_window) >= solved_score:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage score: {:.2f}'.format(\n",
    "                np.maximum(i_episode-100, 0), np.mean(scores_window))\n",
    "             )\n",
    "            if save_filename is not None:\n",
    "                multiagent.save(save_filename)\n",
    "            break\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution\n",
    "\n",
    "Start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Crawler.app\"`\n",
    "- **Windows** (x86): `\"path/to/Crawler_Windows_x86/Crawler.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Crawler_Windows_x86_64/Crawler.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Crawler_Linux/Crawler.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Crawler_Linux/Crawler.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Crawler_Linux_NoVis/Crawler.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Crawler_Linux_NoVis/Crawler.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Crawler.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Crawler.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: CrawlerBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 129\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 20\n",
      "        Vector Action descriptions: , , , , , , , , , , , , , , , , , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Crawler_Windows_x86_64/Crawler.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 12\n",
      "Size of each action: 20\n",
      "There are 12 agents. Each observes a state with length: 129\n",
      "The state for the first agent looks like: [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  2.25000000e+00\n",
      "  1.00000000e+00  0.00000000e+00  1.78813934e-07  0.00000000e+00\n",
      "  1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  6.06093168e-01 -1.42857209e-01 -6.06078804e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.33339906e+00 -1.42857209e-01\n",
      " -1.33341408e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -6.06093347e-01 -1.42857209e-01 -6.06078625e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.33339953e+00 -1.42857209e-01\n",
      " -1.33341372e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -6.06093168e-01 -1.42857209e-01  6.06078804e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.33339906e+00 -1.42857209e-01\n",
      "  1.33341408e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  6.06093347e-01 -1.42857209e-01  6.06078625e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.33339953e+00 -1.42857209e-01\n",
      "  1.33341372e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize agent\n",
    "\n",
    "from ppo_agent import MultiAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage score: 84.65\n",
      "Episode 200\tAverage score: 266.36\n",
      "Episode 287\tAverage score: 501.35\n",
      "Environment solved in 187 episodes!\tAverage score: 501.35\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "multiagent = MultiAgent(\n",
    "    state_size=state_size, \n",
    "    action_size=action_size,\n",
    "    shared_network_units=[],\n",
    "    actor_network_units=[512, 512, 512],\n",
    "    critic_network_units=[512, 512, 512],\n",
    "    value_loss_weight=1.0,\n",
    "    gradient_clip=0.25,\n",
    "    ppo_ratio_clip_epsilon=0.1,\n",
    "    trajectory_length=1000,\n",
    "    gamma=0.9,\n",
    "    gae_lambda=0.95,\n",
    "    optimization_steps=32,\n",
    "    batch_size=1024,\n",
    "    entropy_penalty_weight=0.01,\n",
    "    optimizer_learning_rate=5e-6,\n",
    "    optimizer_weight_decay=1e-4,\n",
    "    optimizer_epsilon=1e-5,\n",
    "    std_init=-2.5\n",
    ")\n",
    "\n",
    "filename = 'checkpoint-crawler.pth'\n",
    "scores = train_multiagent(\n",
    "    env, \n",
    "    multiagent, \n",
    "    solved_score=500, \n",
    "    display_every=100, \n",
    "    max_t=1000,\n",
    "    n_episodes=2000, \n",
    "    save_filename=filename\n",
    ")\n",
    "multiagent.save(filename)\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 702.850885657128\n"
     ]
    }
   ],
   "source": [
    "# load the weights from file\n",
    "multiagent.load('checkpoint-crawler.pth')\n",
    "\n",
    "# Run through once with loaded model\n",
    "env_info = env.reset(train_mode=False)[brain_name]            # reset the environment    \n",
    "states = env_info.vector_observations                         # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                                 # initialize the score (for each agent)\n",
    "for t in range(1000):\n",
    "    actions = multiagent.act(states, std_scale=0)             # get actions from model (for each agent)\n",
    "    env_info = env.step(actions)[brain_name]                  # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations                # get next state (for each agent)\n",
    "    rewards = env_info.rewards                                # get reward (for each agent)\n",
    "    dones = env_info.local_done                               # see if episode finished\n",
    "    scores += env_info.rewards                                # update the score (for each agent)\n",
    "    states = next_states                                      # roll over states to next time step\n",
    "    if np.any(dones):                                         # exit loop if episode finished\n",
    "        break\n",
    "\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, we can close the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
