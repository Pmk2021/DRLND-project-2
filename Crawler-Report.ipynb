{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we will see an implementation for an optional part of the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawler\n",
    "\n",
    "We apply the same algorithm to try to solve the Crawler problem -- with a few different hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n",
    "\n",
    "Agent hyperparameters may be passed as constructor arguments to `MultiAgent`.  The default values, used in this workbook, are:\n",
    "\n",
    "| parameter                | value           | description                                                                   |\n",
    "|--------------------------|-----------------|-------------------------------------------------------------------------------|\n",
    "| shared_network_units     | []              | Network topology for shared network between actor and critic functions        |\n",
    "| actor_network_units      | [512, 512, 512] | Network topology for actor network function                                   |\n",
    "| critic_network_units     | [512, 512, 512] | Network topology for critic network function                                  |\n",
    "| optimizer_learning_rate  | 5e-6            | Initial learning rate for Adam optimizer                                      |\n",
    "| optimizer_epsilon        | 1e-5            | Tolerance parameter for Adam optimizer                                        |\n",
    "| weight_decay             | 1e-4            | Weight decay for Adam optimizer                                               |\n",
    "| trajectory_length        | 1000            | Number of steps cached before trajectory rollback                             |\n",
    "| gamma                    | 0.9             | Discount rate for future rewards                                              |\n",
    "| gae_lambda               | 0.95            | Interpolating parameter for GAE                                               |\n",
    "| optimization_steps       | 32              | Number of optimization steps to perform after trajectory rollback             |\n",
    "| batch_size               | 1024            | Number of N-agent experiences to collect for a single optimization step       |\n",
    "| gradient_clip            | 0.25            | Clipping parameter for gradient descent during optimization                   |\n",
    "| ppo_ratio_clip_epsilon   | 0.1             | Clipping parameter for the policy loss function                               |\n",
    "| entropy_penalty_weight   | 0.01            | Weight applied to entropy penalty on total loss function                      |\n",
    "| value_loss_weight        | 1.0             | Weight applied to value loss on total loss function                           |\n",
    "| std_init                 | -2.5            | Initialization parameter for sigma                                            |\n",
    "\n",
    "Training hyperparameters are passed on the training function itself, `train_multiagent`, defined below.  The default values are:\n",
    "\n",
    "| parameter                     | value     | description                                           |\n",
    "|-------------------------------|-----------|-------------------------------------------------------|\n",
    "| n_episodes                    | 2000      | Maximum number of training episodes                   |\n",
    "| max_t                         | 1000      | Maximum number of steps per episode                   |\n",
    "| solved_score                  | 400       | Average score required to consider problem solved     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def train_multiagent(\n",
    "    env, \n",
    "    multiagent, \n",
    "    n_episodes=300, \n",
    "    max_t=1000, \n",
    "    display_every=10,\n",
    "    solved_score=30, \n",
    "    save_filename=None,\n",
    "    std_scale=None\n",
    "):\n",
    "    scores = []\n",
    "    scores_window = deque(maxlen=100)\n",
    "        \n",
    "    for i_episode in range(1, n_episodes + 1):    \n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        \n",
    "        n_actors = len(env_info.vector_observations)\n",
    "        score = np.zeros(n_actors)\n",
    "\n",
    "        episode_length_list = []\n",
    "        episode_counter = np.zeros(n_actors)\n",
    "        \n",
    "        for t in range(1, max_t+1):\n",
    "            states = env_info.vector_observations\n",
    "            if np.isnan(states).any():\n",
    "                print('\\nNaN found in states')\n",
    "                break\n",
    "            \n",
    "            std_scale_value = 1.0 if std_scale is None else std_scale(i_episode)\n",
    "            \n",
    "            actions = multiagent.act(states, std_scale=std_scale_value)\n",
    "            \n",
    "            if np.isnan(actions).any():\n",
    "                print('\\nNaN found in actions')\n",
    "                return scores\n",
    "            \n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            \n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = np.array(env_info.rewards)\n",
    "            \n",
    "            if np.isnan(rewards).any():\n",
    "                print('\\nNaN found in rewards')\n",
    "                rewards = np.where(np.isnan(rewards), 0, rewards)\n",
    "                \n",
    "            dones = env_info.local_done\n",
    "            \n",
    "            multiagent.step(\n",
    "                states, \n",
    "                actions, \n",
    "                rewards,\n",
    "                next_states, \n",
    "                dones,\n",
    "                std_scale=std_scale_value\n",
    "            )\n",
    "            \n",
    "            score += np.array(rewards)\n",
    "            score = np.where(dones, 0, score)\n",
    "            \n",
    "        mean_score = score.mean()\n",
    "        scores_window.append(mean_score)       # save most recent score\n",
    "        scores.append(mean_score)              # save most recent score\n",
    "        \n",
    "        print('\\rEpisode {}\\tAverage score: {:.2f}'.format(\n",
    "            i_episode, np.mean(scores_window)\n",
    "        ), end=\"\")\n",
    "        if i_episode % display_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage score: {:.2f}'.format(\n",
    "                i_episode, np.mean(scores_window)\n",
    "            ))\n",
    "            \n",
    "        if np.mean(scores_window) >= solved_score:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage score: {:.2f}'.format(\n",
    "                np.maximum(i_episode-100, 0), np.mean(scores_window))\n",
    "             )\n",
    "            if save_filename is not None:\n",
    "                multiagent.save(save_filename)\n",
    "            break\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution\n",
    "\n",
    "Start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Crawler.app\"`\n",
    "- **Windows** (x86): `\"path/to/Crawler_Windows_x86/Crawler.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Crawler_Windows_x86_64/Crawler.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Crawler_Linux/Crawler.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Crawler_Linux/Crawler.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Crawler_Linux_NoVis/Crawler.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Crawler_Linux_NoVis/Crawler.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Crawler.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Crawler.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: CrawlerBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 129\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 20\n",
      "        Vector Action descriptions: , , , , , , , , , , , , , , , , , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Crawler_Windows_x86_64/Crawler.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 12\n",
      "Size of each action: 20\n",
      "There are 12 agents. Each observes a state with length: 129\n",
      "The state for the first agent looks like: [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  2.25000000e+00\n",
      "  1.00000000e+00  0.00000000e+00  1.78813934e-07  0.00000000e+00\n",
      "  1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  6.06093168e-01 -1.42857209e-01 -6.06078804e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.33339906e+00 -1.42857209e-01\n",
      " -1.33341408e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -6.06093347e-01 -1.42857209e-01 -6.06078625e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.33339953e+00 -1.42857209e-01\n",
      " -1.33341372e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -6.06093168e-01 -1.42857209e-01  6.06078804e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.33339906e+00 -1.42857209e-01\n",
      "  1.33341408e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  6.06093347e-01 -1.42857209e-01  6.06078625e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.33339953e+00 -1.42857209e-01\n",
      "  1.33341372e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize agent\n",
    "\n",
    "from ppo_agent import MultiAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage score: 85.62\n",
      "Episode 200\tAverage score: 152.63\n",
      "Episode 300\tAverage score: 220.13\n",
      "Episode 400\tAverage score: 291.78\n",
      "Episode 500\tAverage score: 377.43\n",
      "Episode 527\tAverage score: 400.94\n",
      "Environment solved in 427 episodes!\tAverage score: 400.94\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xd4XdWV8OHfUi+WJVuWe5W7jY0BV2wwPbQACRBIMoTiBEiYVOZLIAkEyISBJAMhA2FwhoAJPaGX0GwDxoCNDbZx70UukmxZvdy2vz9O0S3nSrKtq7re59Gjc/Y592ofkO/SbmuLMQallFIqWlJ7V0AppVTHpAFCKaWUJw0QSimlPGmAUEop5UkDhFJKKU8aIJRSSnlKaIAQkZ0i8qWIrBKRFXZZbxF5V0S22N972eUiIn8Wka0iskZETkxk3ZRSSjWtLVoQpxtjphhjptrntwALjTGjgYX2OcB5wGj763rg4Taom1JKqTjao4vpYmCBfbwAuCSs/Alj+RTIE5EB7VA/pZRSQEqC398A74iIAR4xxswH+hlj9gMYY/aLSF/73kHAnrDXFtll++O9eZ8+fczw4cMTUnGllOqqVq5cedAYU9DcfYkOELONMfvsIPCuiGxs4l7xKIvJAyIi12N1QTF06FBWrFjROjVVSqluQkR2teS+hHYxGWP22d9LgJeA6UCx03Vkfy+xby8ChoS9fDCwz+M95xtjphpjphYUNBsAlVJKHaWEBQgRyRaRHOcYOAdYC7wKXG3fdjXwin38KvAdezbTTKDC6YpSSinV9hLZxdQPeElEnJ/ztDHmLRH5DHheROYBu4HL7fvfBM4HtgK1wLUJrJtSSqlmJCxAGGO2A8d7lB8CzvQoN8BNiaqPUkqpI6MrqZVSSnnSAKGUUsqTBgillFKeNEAopVQ723SgiuU7ytq7GjESvVBOKaVUM77ypw8B2HnPBe1ck0jaglBKqQ5iTVE5pVUN7V0NlwYIpZTqIC56cCnn/3lJe1fDpQFCKaU6EG1BKKWU6vA0QCillPKkAUIppZQnDRBKKdWJlNf6uPjBj3hrbeKTXWuAUEqpTqTeH2J1UQWHa/0J/1kaIJRSqhMJhEIAJCd5bcLZujRAKKVUOzHGUOsLxJTvPFjD0q0HOVBRD8A/VxZx4f8swRhDIGjtxJyanPgAoak2lFKqnTzy4Xbu+dfGmPLT/vi+e7z+rq9wywtrCIQMW0qqSbI2YSM5KfF/32sLQiml2snra/Y1e48/YJgzug8AH2wq5YvdhwFIbYMuJm1BKKVUOxGa/5APGkPv7DQAHv5gG2U1PkDHIJRSqsspq/Fx64tfUu8P0pLP+EAo5I47OMEBIDU58R/f2oJQSqk2sKeslgOV9bz0xV6eWb6bE4bmkdSCCBEIGnfmUri2aEFogFBKqTZwyu8XA3DR8QMBaxaSM+DclJue/pwvdpfHlKe0wSwm7WJSSqk21BAIApCSlNSiLiav4OC8PtE0QCilVBuq9VkBos4fbFELIh5tQSilVBdTUWelyKhtCHgGiJYOLaToLCallOpaDlVbM5FqfEGOoQGh01yVUqqr2VteB0B1nBZEyLTsfdpimqsGCKWUOkb1/iCPL93Bqj3lPPnprha9pqYhEDHNdWZh7ya7jaKv6TRXpZTqBO57dzPzP9zunv/bzGEEQ4bbXlnLdbOHM6pvTsT9g/IyqWmIXCh33MBcZhX24f73Nnv+jNzMVA6FL5Rrg1lMGiCUUuooPbZ0Bx9tOUjIRPYLBUOGbaXVPL1sN08v282lJw6OuJ6dnmy1IMK6mJKTpMmZSblZkQEiWbO5KqVUx3Xna+sBmDQoN6I8OoX3C58XRZxnp6dQ4wuQnpLsliUnSZMpvHPSIz+u2yJZn45BKKWU7b/f2cT973p38TTlYHVDxHmtLxjTqgjXIz2FqvpAxCwmK0DE/0jOTEuOONdZTEop1Ybe31TKJ9sOued/eHsjt764BoCqej8/fW4V5bW+mNeVVkUGiJqGAP6Ad4BIEijokU5pVUPEGESSCClNBIistMgWRFP3thYNEEopZatpCOAPS4z30OJtPLN8DwALPt7JS1/s5a9Ltse8LhA1N7XWF3RTakSbO6aA/rkZFFfWEwzLwZecJG63Uc+MFF74/qyI12WmRrYgdKGcUkq1oaqGgJtaO9y42/7Fg4u3AnC41s/ijSVNvo8VIGIzsF564mAe+vaJDMjNIBAylFTVu9eSk8RNwzFlaC96ZaVFvDZ6yYSm2lBKqTZUXR/AH4z9YK/3h6j3W+VPL9vNtY9/RsDjPkeNL0C9P7YFcdKwXmSlpTAgNxOAosN17rUkEWaP6sOMEb35/aWTY8Yjooc0NFmfUkq1kUAwRJ0/GNNdFE+tRwBwrzVEtiAKctIBOGyPX/TPzQAiNwBKSRLG9s/huRtm0T83I2YQ2hBZLx2kVkqpBKio9WOi/iSvabA+8JtqGYSr88UPEDW+QMQYxGR7GmzQDj6j+/WImbYavXlQdBdSKASzR+W3qG6tRQOEUqpb2Vtex/F3vcP/LdkRUV5tr13w22MQXl1N4WqbCBB1vqDbJQXw7ZlDueOrE/jeKYUApKckc+3s4RGviR5SiO5CMhie+u7MJuvU2hIeIEQkWUS+EJHX7fMRIrJMRLaIyHMikmaXp9vnW+3rwxNdN6VU93Ogwur3/92bG1i1p3Eznup6K0A423vWNARiXxymqeu/eXVdRPdRZmoK18weEbGWIaOZdQ0xLYgWJvFrTW3RgvgxsCHs/F7gfmPMaOAwMM8unwccNsaMAu6371NKqVYVPvh7yUNL3ePqBmufBmcWU1V90wGirokxCIDlO8rc44zU2I/ajJTIABHTxRQ9BtHVAoSIDAYuAP7PPhfgDOCf9i0LgEvs44vtc+zrZ9r3K6VUixljWLyphFCcP7njDe46AcHpWqrxNR0g4nUx3X7hBAA+33XYLUuPCgbgsTJaogNE9Cymto8QiW5B/An4OeB0xuUD5cYY5798ETDIPh4E7AGwr1fY90cQketFZIWIrCgtLU1k3ZVSndDra/Zz7WOf8eQy77TboThDC9UNTheT9UFc3VwLIk4AuWjKQAblZVIV1gXl1YKIXvjWXAsi3eM9Ei1hP1FELgRKjDErw4s9bjUtuNZYYMx8Y8xUY8zUgoKCVqipUqorcTbk2Ru2xiCcP06EcMcgnC6mZsYg4rUgUpOS6NszPaIsPTW2BZHRzMro8IDx76eP4rcXH9dkfRIhkdlcZwMXicj5QAbQE6tFkSciKXYrYTCwz76/CBgCFIlICpALlMW+rVJKxedMJY3+i9zhtVIaGlsQTgBprgXx9zgbA6WmCDkZqRFlGSkeLYgjSL73H18Z22RdEiVhLQhjzK3GmMHGmOHAlcAiY8y3gcXAZfZtVwOv2Mev2ufY1xeZ9uh0U0p1ak6AiJerKBDVgjDGMP/DbWwprrbP4fZX1roBI54vdpd7lqckJcWscfBsQUQFDa/tR9tbe+wH8QvgWRH5T+AL4FG7/FHg7yKyFavlcGU71E0p1ck5Ywjx/iKPbkGs21fJ3W9ujCh74pNd/Or88Uf181OThZyMyI/WY21BhLv7a5PYX+Hdfdba2iRAGGPeB963j7cD0z3uqQcub4v6KKW6Lmf2UvSsIEd0C2LjgSrP+6rq/YjA5ScN5vkVRZ73OJKkcZ2CiNAjrAVx0rBenqm5owepm9o/Ity3Zgxt0X2tQVdSK6W6FGeaarycSv6oFsSXRd5dRQdrfPRIS+HeSydz3nH9m/yZaVEtBGcM4oxxfXnh+yd7viZ6kDp85XVHoQFCKdWlOOsXvLKpQmwX04HKes/7DlTU0yMjBRGJCQDRbr9wYsS508WUlRY79uCI7mKKt39Ee9IAoZTqMj7eepAnP90NNBEgorqY4g1GbympcruKmtoK9OpZw2K6fZzWQXQrweseh1cL4pnvzWTxf5wW9z0STQOEUqrLeHr5bvc4XpdNdAviYFXsFqIAe8rq3O6q1Ki8SOlhLYqJA3NjXusEp+hxhnDRA9deAW3WyHxG9MmO+x6JpgFCKdUprdx1OGYtwsiCHu5xnT9IRa2f+9/d7E59hdgWxMHqxv2ko6fG7jxUC8S2IJwupF9fMJ7Lpw6OqZszIym/R1rMNfdnJSfRMyOFWYVWwojRfXvEvbe9tMc0V6WUOmaXPvwxAFfNHOaWhffr1/uD3PX6el74vIjJg3M5c3w/oHGQ+mdnj+G+dzdzKCzr6rD8LLaV1sT8rNgAkcrBah+j++XglTLuimlDKKvxccOpI5t8hjV3fAWAHQdr2rWlEI+2IJRSXYYvbBe3+kDIbR2EL0JzNgQ6fkhezOuvOXl4xPkfLpsMxOYBcloQfo99p8EaX/jp2WNiBqLj6YjBATRAKKU6ufCNfRoCQZKThJmFvan3Bd2U3OF/5DvTX0cWNH4o33BqIatvP8fdK9px+dQhANRHzTD6wWmjAJg8JHb8oSvRAKGU6tDq/UHe31QS93p40jxfIERachIZqcnUB4LuwG/49qBOgMjPTnenoeZkpJCblRqzSU9jHSJbCqeNLWDnPRfQNyfj6B6qk9AAoZTq0O56fT3XPPYZG/ZXumXhez3UhqXdbgiESEtJIjM1mXp/Y4AIDyJOF1NyklCQY2Vdzbans4bPb/rrd6a6x9GbA6V5THtdffs5rPz1WUf6eB2aBgilVIe22U6FEb5e4XBt48Dy6j0VTLz9LYoO1+ILhEhPSSIzLZmahsYupvAg4gxSpyYLA+0upew0K0AE7WtnjOvL2RP6ua+pj0rt7ZUpNjcrlfwe6THlnZnOYlJKdWhBO0dR+EdyadjU1PkfbqPGF+SddcVWF1NKEnmZaVTU+d3FaBEtiFCI5CRBRBjcywoQzipmZwps9HTX5rYX7aq0BaGU6rD2lNW6abXDxwH2lDVmMy2zp6ku3lRCWa2P9JQkemWlUt0QoKzGCiQ1EV1Mxg0AU4ZaM5mcaazO+ET0WESP9O75t3T3fGqlVIcXCIY45feL3fPwbqI9ZbXusRMglmw5CMD4AT3Jy7KS5TlDFX9euIWRBdlcPGUQ/qBxA8K3pg+ld1Ya50y0kvH1tJPsDe0dOe30nksnc/LIvdzx2vrWfMQOT1sQSql24w+GmPuHxbyz7kDMtf0VkUn0wruJ9hxuDBCVUTu/paUkkZsVu4L5x8+uAiBodzGBlZr7vEkD3PNTRvfhL98+kZ+dPSbitb2z07hm9ogjebQuQQOEUqrdlNX42HWoll+9vDbmWnRuoogAUVYXN89RekoSeZmpntcqav34QyYmt5JDRDh/0oBms7d2F9rFpJRKmC+LKgiEQpwwtJfndedj2mt34ei1B+FdTKVV9Qzvkx0x9dVhjUF450DaXVZLIBgiJenoAsBLPziZkqqG5m/sIjRAKKUS5qsPfgTAznsu8Lzus9ckeO3tE716ObwFcbjWz5h+OZ4BIi05idw4LYhdZTXWIHWcFkRz4gW6rkoDhFKq3ThrEoIeEaKpLqbDtT4G5mWQk55CVdR+DumpSe4CuJ+fO5ac9BQq6wP84e1NbC2ptruYtAupJTRAKKUS4vPdh5u9x0mu57Ufc3QXU01DgNtfWcsV04ZQVR+gd3YaS289g0PVPk7/4/vufWnJ1kK5rb87z13vAPDO+mIWbSxhUF5mzDoH5U3DqFIqIb7+l4+bvcdJtGcM7K+oi7jmtCD+Pm86vbJSWbuvgic+2cXVf1sOQK+sNHpmpMZkQnUGmFOSkyJScZ8zoR9riirYVFzlzlpSTdMAoZRqE8YYlu8owxjD1pJqvv/kSncvhuqGALP+axEbDzSOKTgBYljvbHplp7G/3Jr22mC3LJy1DtHSU7xnN43tlwPA9tIaRnbAzXk6Ig0QSqk28cQnu/jGI5/w/qZSXvqiiH+tPcB972yKuOdrD33MrkPWhj31dvdTRmoSPTNSOVAZuS4iL2ym0rPXz3SP401RHZqf5R7/5qsTju1hugkNEEqpNvHehmLAmrmUl2l9uK8uqoi4p84f5L/e3AhAg92CSE9NZqa9LSc05mbqFdaCmFmYz/QRvQFrUZuXob0bA0RXT9PdWjRAKKVande6hi3F1YD1F36NLxBz3bHjYA13vLrOnbWUkZrEVyY2Zlat9QVJEigsiOwmKrczvA7M8/7wz4izsE7Fp7OYlFKtzheM3YrT6SLyB0LUNMQPEJuKq9hUXMWZ4/oiYs1KmhK1PeiYfjkxCfQO1/oB3BTeXp6/YRb5PbxbGCqWtiCUUq3OF2evZrDWPtT4mk+fvaWkmoyUZESsqaovfH+We23SoNitPhtbEPEDxPQRvRlZoAPULaUBQinVpD1ltewrr2v+xjDOAjjHuNv+5R4HQk23IBy7y2rJSG38iDppWG9G27OPvGYwOZlY++fq+EJr0QChlHJtLanm5/9cHbGy+ZTfL+bkexa16PW+QIjfv7WRg9WR+YrCF735AiFqGoKktyAhXvS4gbMCOisttnf8+Rtncf8Vx+sq6VakYxBKKddNT33OpuIqrp09gvEDeh7x65duPchf3t/G0m2H4t7jDxpqGgL065nB7rB9HbxEBwhnxXV2euyA88iCHtp91Mo01CqlXM6Wm14rjYff8gbDb3mDB97bAsA76w4w6TdvR2RZdRYur95THvdn+IMhan0B+vdsvisoOqW307LxakGo1qcBQinlcnqWmkpEcf97mwH47RvrqWoIcCBsY5+ahuYHn/3BENUNAfrkxJ9NlGZ3ExUWRKbRcAKEVwtCtT4NEEopl9OC8JqmGs0JBs4+zt9dsIJHP9re7Ot8wRC1viDZYa2AG+eOjLinjz0VNbqVEdAWRJvSAKGUctnxoclpqo5qe6vP6oYAh2t8vLehmM93x+9acvgDhso6P9lh6xhuOW9cxD3fP30U04f35runFEaUuy0IDRBtQv8rK6VczgdwcwEiEAy5rYzahiCbiqta/DM2FVdS4wsyrn9O3HsmDcrlqpnDYn+uHcGytIupTWgLQinlcvIcNdfF9KuXGveQrm7w87PnVrX4Z7z55QEAZoTlVwL41fnj3WNnw5+Y+rldTBog2oIGCKWUKxTWgnhjzX7OCNuIJ9xzK/a4x5uLq9lXUe95Xzxj++UwPCy7KsD3Ti3k0hMHA5AfJ+FeQLuY2lTCAoSIZIjIchFZLSLrROROu3yEiCwTkS0i8pyIpNnl6fb5Vvv68ETVTanu7LGlO+Lu9uZ8AB+q9nHzP1ax/WBN3Pdx/op3Nvq5+2uTmvy5Pz93rHt80xmjIjbzceRlpdKnR1rcxHrBoLYg2lIiWxANwBnGmOOBKcC5IjITuBe43xgzGjgMzLPvnwccNsaMAu6371NKtbI7X1sfd7c3pwvn5y+sidnyM9q5E/sDsM/eyCd6Z7doPzhtlHvcwx5D+Ns1U/n1BePD7hnJk9+dEfc9nER7mRog2kTC2mnGyvdbbZ+m2l8GOAP4ll2+ALgDeBi42D4G+CfwoIiI8cobrJRKiPAUG80Z1c9atey0IOLt8ObF6SI6Y1w/zgibwJTfI538Ht7jDwBPfncGS7ce1GmubSShYxAikiwiq4AS4F1gG1BujHGWXhYBg+zjQcAeAPt6BRA5iqWUOib+Zgafg0fw99j4/j3JTE12twLNzUxl0qBc+sYZYA6XnX50H/CDe2VxxbShR/VadeQSGiCMMUFjzBRgMDAdGO91m/3da/FmzG+riFwvIitEZEVpaWnrVVapbsDZ59k5dlJkO0ItaEHMLOzNNScP57SxBWSnJ1NlZ2bNy0rltR/O4Zmw7T8dKVGpO6L3clAdU5vMYjLGlAPvAzOBPBFxfjsGA/vs4yJgCIB9PRco83iv+caYqcaYqQUFBYmuulJdSl1YgPjj25u4cv6nEdfjtSCOH5zrZl/94RmjueOiiYiI29WTmixu3iSvGUbRGVaPtgWh2lYiZzEViEiefZwJnAVsABYDl9m3XQ28Yh+/ap9jX1+k4w9KtZ5gyPDLF790z3ccrGFv2D4PoZAh3r+4G+eOdGcWhafpdmYT5WamurOSemR4BYjIFoTmUuocWhzGRWQOMNoY85iIFAA9jDE7mnjJAGCBiCRjBaLnjTGvi8h64FkR+U/gC+BR+/5Hgb+LyFaslsOVR/E8Silg8h1vM6Mwn/X7Krnn0kmcMrqAtXsreG9DiXvPoRofNQ0BjDGICOV1/rjvF94CSE9p/HBPt4OGs1kPWN1Hj10zjROG5vHXJdt5aPE20qL2fojO0qo6phYFCBH5DTAVGAs8hjUj6UlgdrzXGGPWACd4lG/HGo+ILq8HLm9RrZVSTaqsD/Du+mIAfvLsKlbedjZlUeMNZTU+QsbazCczLZlDUZv8hEtLSXJTeaeH7fKWYX/wR3cZnT6uLwAzRuRbASKqi8lrDYTqeFragvga1of95wDGmH0iEj+RilKqwzhU4+PT7Yditg0tq7ECRnVDAF8wxNaSaq+XA0S0AMK7mJwWRLwWgTM4Hd2CUJ1DSwOEzxhjRMQAiEjTK2KUUh3KlfM/5dQxkZM6qu3ZRzUNAab97v0mX5+SJO74RPiHvdOCyIizcM3ZeEi3Ae2cWhognheRR7BmIH0PuA74a+KqpZQ6WvHWOny42XtauBMomhIIm/4a3l2U4bYgvANASnJkC2LBddM5XOPzvFd1PC0KEMaYP4rI2UAl1jjE7caYdxNaM6XUUQlf69ASD3+wzT1OEuuvfn8wcjpTIGgYlJdJRZ2flKTwAGEdNzfo7LQg5o7RqemdSbMBwp6F9LYx5iys1dBKqQ6sLk6AePzaaVzz2Gcx5W+s2e8e52WlUdMQIHqN6tDeWTx+7TQ+2X6I3LCUGm4LIk7qC1/Aeh8dg+icmv2/ZowJArUiktsG9VFKHaF6f5DwJUMNcZLsnTa2b7PvlZ2ezKi+Pdzzcf1z+PKOcxian0XfnhlcPGVQxP0ZzQxSO91d0bOYVOfQ0v9r9cCXIvKoiPzZ+UpkxZRSzauo9TPutrf43w+svaC3llTx9roDR/1+2WkpHD8kzz2/dvZwcjLiJ+FzB6njjEGE7MClC+M6p5YOUr9hfymlOhBnbcNTy3bxvVNGcNZ9HzZ5f6+sVA7Xxl8Ql5aSxC++Mo5QyPDLC8ZHLIDzkmyPRyTFWdcwZ1QfvnfKCG6YO7LJ91EdU4taEMaYBcAzwEr762m7TCnVypZtP8Srq/fFvV5V73e7lJwunIZAiI0Hmt8X+uWbZjN9eG/3/IdnjIq4LiLkZqVyz6WTmw0OAMYeq4i37i0lOYlfXTCBPk2k8FYdV4sChIicBmwBHgL+AmwWkVMTWC+luq0r5n/Kj575wj1ftv0QT3yyE4A9ZbVMuuMdnvx0FwC1PmtA2hcIuQvfvFw1cxgAw/KzuW7OCLf85nPGRtyXfIQLnJ2hD10X3TW1tIvpv4FzjDGbAERkDFaL4qREVUyp7qTWF6CsxsfA3MyYa1fYGVevmjmMbaXWaue31xVz1azh1NprGBoCwbi5lLb87jySw/7EP22sNdW0p51Ub8F10/lsRxkPLt4at6soHndoXFNndEktDRCpTnAAMMZsFpGWbx+llGrSvMdX8Mn2Q7z3s7lu2a5DNQzLb0xaUNUQcAd9k5KEUMjw/Io9gNXFVFHr3YKIXsWckZrMwpvnumkw5o4poMGeGpuUdHRNCA0PXVNLA8QKEXkU+Lt9/m2ssQilVCv4ZPshAFbtKXfL5v7hfd740Rz3vLii3l1X8OHmUgp/+aZ7zRgob2LwOdrIgh4R58501SOOD/Z3bUB0TS2d5vp9YB3wI+DHwHrgxkRVSqnuYNOBKm57eS2hkHH/mv9sR+QeWU98vMs93l9R32RajKbSdTfH+YA/0i6mMf1yIr6rrqWlLYgU4AFjzH3grq7WaQlKHYPvPvEZe8rquP7UQnIyUjhc6+c5u8vIsXZfhXt8oKKeGl/8ALH3cF3ca80J2rmWko+wCXHh5AEUFmQzcaCuo+2KWtqCWAiEj55lAu+1fnWU6j6cGUCBkPHchQ1g3b5K97ikqp6q+vgBYnVR+VF39QzpnQXAqaOPLFeSiGhw6MJa2oLIMMa4yeKNMdUikpWgOinV5fmDIRoC1hqGWl+AnPRUwGoB3PP1SdwStjXo4F6ZFFfWU+ML4g94p9EAqwtqeH4WOw/VAvDFbWfH3WM62siCHnx665n066kdA6pRS1sQNSJyonMiIlNxfpuVUkfs2sc+o7TK2sGtpiEY0YI4cViviHsnDcolMzWZOl+wyRYEROZb6pWddkQL1PrnZuhObypCSwPET4B/iMgSEfkQeBb498RVS6mu7aOtB93jGl/AHaS+auawmMR2/XpmkJWWQq0vQFWD90B0YR9rOuxXjx8AwPWnFiai2qqbabKLSUSmAXuMMZ+JyDjgBuDrwFvAjjaon1JdSr0/yCur9kaU1TQE8AdDzCrM566LJxIIGU4fW8DBah9f7q2gf24GWWnJ1DbRgnj9R3NYt6+Sk4b1ZuNvz9XsqapVNPdb9AjgrL6ZBfwSK93GYWB+AuulVJf05pf7+cULX0aU1TQE8AVCpKcmISKkJifx2LXTmTCgJwA5GSlkpVtdTOGbAQ3Ky+S0sQV89quzyEpLYZqdYykjNfnIF7wp5aG5QepkY4wzMfsKYL4x5gXgBRFZldiqKdX1bCmpjil74L0t7Kuo55wJ/SLKa+1gkJWWTFZqCjW+QMRmQEt+froGApVQzbUgkkXECSJnAovCrrV0BpRSyrbNI0Dsq6gHYnddu3LaEABmjMgnMy2ZjQeq2FdeT2GfbH57yXEaHFTCNRcgngE+EJFXsGYtLQEQkVFARVMvVKq7MMaw+1Atr6zaS70/SEWdn1+99CW1vgDGGG5/ZS2PL91BRZ2fraWxAcIRPW4we1Qfdt5zAQPzMslKS6a81k9ZjY8Th/Vys7MqlUhNtgKMMb8TkYXAAOAd07ivYRLww0RXTqmOxBcIcfM/VvP1Ewcxe2Qf9y/+RRtLmLdgBWDNHgqFDE8t2824/jkU5KTzxCdWuow7Xlvf5Ps3tW9zeti1rDTdnU21jWa7iYwxn3qUbU5MdZTquHYcrOG11ft4zd4xKrVsAAAZuklEQVTMJz87jXd/NpfVYQn29pbXuWm0b3tlHWPtHEVpyUn47M19Jg3K5cu9sQ3wpgJEja9x7CHe/s9KtTadC6dUC5VU1UecH6rxsXxHGZuLG7uNNh2o4pnljfmUNhVbu7w5wQFwZyc5vjl9KNB0yuyKsER8GRogVBvRAKFUC2wtqXL/6g/v7qmo87G5pCrsvtgxhujFyaP7NabazkpLZqx97gvGT4tRGRYgMrWLSbURDRBKNWNbaTVn3fchv3/L2jNrVN/GD/iSygZ22bmP4pk0qDGZ3Z0XTaRXVpp7Pm/OCLLSrS4pXxN5lsJ/pnYxqbaiAUKpZizcUOwe56SnkJ3WOHT3+e7DbqrseI4LCxCXnjSYiYOsLqb7rziem88Z67ZIGgJBz9cD3HvpZAblWQmVNUCotqIBQqlmhO/UFt1d9NnOw82+PrwFkZ2WzLj+PVl9+zl87YTBQGOXVVMtiOz0FGYUWiuldf2DaisaIJSK4g+GKK5sHJB2BoinDe/FHy8/PuLe6oZAs3mPjh+c5x472VJzsxq3dHf2jPYH4wcIwE3oF2qmxaJUa9EAobqlpj6Mf/HCGmbcvRBfIMRTy3bx1LLdjOiTzT9uPJlzJvbHEPkBPX1Eb3LSG7ud5ozq4x5/+P9OZ8LAntxy3jhumOudYdWZ3uprJkA4u70FNECoNqIBQnU7tb4Ac+5dxE1Pf+55/cXPrWyrmw5U8auX1gLQIywARK9XOG1sAZ/9+ixusFNsh89yGppv7at149yR3HreeM+fN214b04dU8DtF05sst752dbeDhmp+s9WtQ3Np6S6nfc2lFBc2cAba/Zz50UNcTfV+eqDH7nH4QPI9146mfkfbqegRzr/WnuAf5s5jIzUZCbaYw0Ha3wx79WUjNRknrhuerP3/fsZo8jLSuXiKYOO6P2VOloaIFS388m2Q+5xbUOQYJbBFwiRmZYcdyZRTUNj+eBeWdx18XEA/PDM0W75qAJrKmpJZeSCutaSkZrMd0/RjYBU29G2quryAsEQV87/hCVbSgE4UNG4W26dP8itL65h/O1vsWpPORc/uNTzPWp8TW/1CVBYYO3qNndMAe/89FRevml2K9ReqfaTsBaEiAwBngD6AyGsvSQeEJHewHPAcGAn8A1jzGGxpnc8AJwP1ALXGGO8O4mVOgKl1Q18ur2MdXs/572b51Jc2UCSQMhY4xHPrygC4JKHvIMDQG5matxrjozUZJb98kx6ZaU1mVdJqc4ikb/FAeBmY8x4YCZwk4hMAG4BFhpjRgML7XOA84DR9tf1wMMJrJvqRpxpqlUNAWbcvZD1+ysZnm/9te+1hee4/jkxZQuubX6MAKz9ozU4qK4iYb/Jxpj9TgvAGFMFbAAGARcDC+zbFgCX2McXA08Yy6dAnogMSFT9VPdxuMYfUza8jxUgbn9lbcy1E4bmRZz/5yXHufcr1Z20yZ86IjIcOAFYBvQzxuwHK4gAfe3bBgF7wl5WZJcpdUzKa2NnFTktiJ2HainIiZzFdOPcke7x0lvO4Nszhia2gkp1UAkPECLSA3gB+IkxprKpWz3KYlYEicj1IrJCRFaUlpa2VjVVF3a4NrYFEZ78bmZhvnv88k2zGZbfONg8KC/TXf2sVHeT0AAhIqlYweEpY8yLdnGx03Vkfy+xy4uAIWEvHwzsi35PY8x8Y8xUY8zUgoKCxFVedRrGGJbvKIvJZWSMoaLWz2G7BbHy12e5144b1LgnQ9+cdB64cgqTB+e6gWPzf57Ho1dPbYPaK9VxJSxA2LOSHgU2GGPuC7v0KnC1fXw18EpY+XfEMhOocLqilPLy6Ec7OOm373LvW5v4xiOf8Na6A9z28lr+b8l2AJ5atpvj73qHNUXlZKQmkR+2IG5kQWMLoiAnnYunDOLVf5/jrphOS0kipZkcS0p1dYlcKDcbuAr4UkRW2WW/BO4BnheRecBu4HL72ptYU1y3Yk1zvTaBdVNdwG9ft/Z4fuTDbYA1W+nvn1r7P597XH/eXncAgJW7DkfswQCR+zoXxFlJrVR3l7AAYYz5iPi7KJ7pcb8BbkpUfVTX8ce3N7Fk60H33NgjVbsO1rhlc+5dzOljrS7Ig9U+d+rqY9dOIxg0EeMKfXI0QCjlRVNtqE7nwcVbPcudLUEd6/Y1zolwWhCnj+1LNK91D0opTbWhOqDyWh+/eWUt9f7YvEh1vvi7rq3aUx5xXlLV4B73yo6/Erpfz4yjqKVSXZ8GCNUujDF8sLkUY0xM+X3vbmbBJ7sYd9tbbC2pjrg+/va34r5nQyBEv57pfH7b2fz0rDER1/KixiAAbphbyO0XTjiGp1Cqa9MAodrFi5/v5eq/LecfK4vcsjVF5Zz3wBKe+GSXW3aXPRANUFkfu57B4ezXPHdMAb2z0/jaCZFrLHtlxbYgbj1vPNfNGXHUz6BUV6cBQrWL3WW1ABTZ37eVVnPRg0vZeKAq4j5/oHH7z72H64h22UmDee3f57h7RR9n78kwND+LX5w7zh1f6JnRfLI9pVQkDRCqXbgdS/Yn+33vbPa875Pth5hx90KKK+vZYweTcJdMGcSkwbmU26ulB/fKdK99/7SRnD2hH2DtHa2UOjIaIFT7CBt78AdDLN5U0sTNsKesliKPFkS6vf2mEwCG9MqKuD7LTqMxVmcqKXXEdJqranPbSqv58yJrqmpDIMiaonJqfUEunjKQV1bFZFcB4E/vbeGjsLUPjvSo1NqDwloQACeP6sNHvzjdHaNQSrWctiBUmwtPsV1Z53fXK5wzoX/c13gFB4D0FGtF9JXTrDReWWmxf/MM7pWlCfeUOgraglBtxhcIcfebG6isaxwPeG9DCc8s30N6ShITB/Zs4tXenBbEPZdO5u6vTWq1uiqltAWh2tDCDcU8/vHOiBXPpfZiNhFi9mX4/aWTuf3CCW759BG9ee76me7ez9A4BgGQlKStBKVakwYI1Wb2VdTHvVbvD5GdnsKC6xq39vzGtCFcN2cEp4zqA8C5E/szozCfRTef5t6TphlXlUoY/delWtX9727mjP9+P2JKar0/yK0vruHBRVvcsuQk4Rx7CipY6xkAhvWOnIUEuFNVwzf5caSnJseUKaVahwYIdUTW76tk44H4GwO+unof20treG2NNRvpUHUD4257i2eW74nY2e3kkflcO9taxXzecf255+vW+EGGxwf+eZMG8OH/O51Tx8RuEBU9i0kp1Xp0kFodkfP/vASAnfdc4JbV+YJkpCYhIu7ubcV2d9Kzn+2JfROs3EgzC3vz20uO49yJ/d3NeTLjtAiG5se2LABSdNxBqYTRP7/UMdlTVsv429/iHyuLOFzjc1c0L/hkF0u2lLI6KsOqIzczBRHhqpnDIganwwedW0KnryqVONqCUEdt/ofb2FJsZVt9Z90BRvTJjrh+1aPLmTiwJ3PHFJCbmcqrqxsXwfX2yK4K2mWkVEeiAUK1WEOgcS+G3YdqufvNje55VloKH2895CbNczJprNtXybdmDI3pChrVzzv1hbYIlOo49M811WJlNT73+NQ/LI64lp6SxLsbDjB5UC5XzxoecW1QXiahqH0fJgw4ttxIf7hsMt+ZNeyY3kMp1TQNEKpZa/dW8NrqfRyq9sW95x8ri1i7t5JvTBvCry8Yzzs/PdW9NiA3g1BkfGB4fjZN6dOj6X2iL586hLsuPq75yiuljpp2Makm1TQEuHL+p1Q3BPjG1MFN3jt1WC++MXUIKclJjCpoXLMwtn8OkwblWiupr51OyBh31pKXD//f6eRk6K+mUu1N/xWqJr2/qdRNpf3+ptIm7/3RmaNJtT/4w9NejO/fk6QkYdkvz2rRz4w3pVUp1bY0QCgAQiGDiDVI/Me3N/Hamn38+coTWLbjEFlp1tqEEjtvUjwnDesVcX7F1CEEQkZzJCnVSWmA6OaeXrab8QNyeHtdMc9+tptaXxBfIARYabkPVvs4aVgv9pTVsvNQLYUF2WwvrYl4j5+fO5aJA3PJTo/8dbr3sslt9hxKqdanAaKbKavx8d76Yi6aMpDzHljCjoPWh31WWjK1vmDEvauLrKyrv71kIr97YwMA35w2lMmDc7nhyZXuorhTRxe4e0ErpboOncXUzVz45yX8/IU1vLX2gBscgJjgED6F9PSxfalpsK4P7pXJjMJ8bpw7EoB/3DhLg4NSXZS2ILqJPWW1ZKenuCm3w1c1g5U2Oz01iap6a0D6rPH9qPcHOfe4/ogINT6rfLC95/ONc0e6QUIp1TVpgOhCjDG8v6mUzLRkZhbmY4yh6HAdd762jvc2lETcu2ijdX79qYWs2lPOVTOH8T+LtlBVX83/fPMETh1TEJE9tcFvjUtE7/mslOq6NEB0Ic8s38MvX/oSgAeunML/LNrK1pLqmPu+NWMoTy/bDcAt545zZxlNHNiTl77Yy4WTB8S85ol503lhZRG9slIT+ARKqY5EA0QXUFHn59VVe7nv3c1u2Y+fXRVz34/OHI0A3z1lBE8v282gvMyIKaiFBT24+Zyxnj9jZmE+MwvzW73uSqmOSwNEJ+UPhli0sYTTx/blL+9v5ZEPtgPwzPdm8s2/fur5mp+dPcY9XnfnV9xxBaWU8qKzmDqpx5bu4Ia/r+T2V9ZSVFYHwIQBPZk1Mp+Xb5odc/8fLz8+4jw7PYW+ORltUlelVOekLYhOpt4fpKLOz6Mf7QAad2w7eWQ+f/3OVACmDMlz7191+9nkZKSSrKuZlVJHSANEJ/Prl9fyz5VFAPz+ssnc8sIaQgYunzo4YiXzmeP6kpQk5MXZmEcppZqjAaKTKK6sJycjhSVbrIR5hX2yufykwUwd1ovNxVWce1zkzKNHr5nWHtVUSnUhGiA6gX3ldZx8zyJOGd2HvjkZlNf6efEHJyMiFBb0oDAstbZSSrUWDRAdXGlVA+f+6UMAlmw5CFhZUrXrSCmVaDqLqYMqrqznsaU7mPa796isD/CnK6aQn20FhT45GhyUUomXsBaEiPwNuBAoMcYcZ5f1Bp4DhgM7gW8YYw6LtVP9A8D5QC1wjTHm80TVraP7YHMpV/9tOQDj+ufw7ZnDuOSEQZRWNfC7NzdQUedv5xoqpbqDRLYgHgfOjSq7BVhojBkNLLTPAc4DRttf1wMPJ7BeHVYoZHh62W43OIztl8Pf583gqplWZtVvTBvC3DEFzJtT2J7VVEp1EwlrQRhjPhSR4VHFFwOn2ccLgPeBX9jlTxhjDPCpiOSJyABjzP5E1a+jOVBRz41PrmTVnnIG5Gbw1k9OJTczMu9RbmYqC66b3k41VEp1N209SN3P+dA3xuwXkb52+SBgT9h9RXZZtwgQh2t8zL53EcGQ4T/OGcO3ZgyLCQ5KKdXWOsosJq9lvsbzRpHrsbqhGDp0aCLr1CaMMTywcAvBkOHms8dw0+mjsIZklFKqfbX1LKZiERkAYH93NikoAoaE3TcY2IcHY8x8Y8xUY8zUgoICr1s6jeLKer7+8Mc8/vFOLj1xMD88c7QGB6VUh9HWAeJV4Gr7+GrglbDy74hlJlDR1ccfdhys4WsPLeWL3eWM6deDey+d1N5VUkqpCImc5voM1oB0HxEpAn4D3AM8LyLzgN3A5fbtb2JNcd2KNc312kTVqyMoOlzL959cSZ0/yJPzZjBpUC4pybokRSnVsSRyFtM341w60+NeA9yUqLp0JP5giHmPr2BLSRUPfetE5ozu095VUkopTx1lkLpbqKjzc9dr69lUXMX//ttJnHtc//auklJKxaUBoo1UNwS46MGP2HWolvMn9ecrE/u1d5WUUqpJGiDawObiKu56bT27y2p57JppnDa2QGcrKaU6PA0QCbavvI4r539KWY2PX18wntPH9W3+RUop1QFogEigTQequOnpz/EHQrz9k1MZ2z+nvauklFItpgEiQVbuKuOKRz4lKUl4/NppGhyUUp2OBogEePLTXfz29fUMzMvkqe/OYEjvrPauklJKHTENEK3IGMMvX1rLM8t3U9gnm/+96iQNDkqpTksDRCuo9wfZeaiG+97ZzDvrizl/Un/+cNnxZKfrf16lVOeln2DHqN4f5OIHl7KpuIqcjBR+dMYofnr2GJ3GqpTq9DRAHKWSynre21DCwx9sZU9ZHbmZqTzzvZlMGNizvaumlFKtQgPEETpU3cDb64r5rzc3UNUQAGDenBHcduGEdq6ZUkq1Lg0Qzaj3B1m+o4yPtx1i2Y5DrNpTjjEwZUgeN84tZO6YvmSmJbd3NZVSqtVpgIhijGHdvkreWV/M2r0VbNhfyf6KegCG9s7iZ2eNYe7YAo4bmEtSko4zKKW6rm4bIALBEBV1fraUVLN060Gq6gNsOlDFmqJyanxB974ZI3rzH+eMZe7YAvKz03TwWSnVbXTLAPHs8t3c/eYGKusDbll6ShIDcjM4ZXQBU4f34qLjB4JAQY90DQpKqW6pWwaIAXmZnDm+H2P65ZCbmcrJI/MZ3ie7vaullFIdSrcMEHPHFDB3TEF7V0MppTo03QhZKaWUJw0QSimlPGmAUEop5UkDhFJKKU8aIJRSSnnSAKGUUsqTBgillFKeNEAopZTyJMaY9q7DURORUmDXUb68D3CwFavTUelzdi36nF1Lez3nMGNMs6uFO3WAOBYissIYM7W965Fo+pxdiz5n19LRn1O7mJRSSnnSAKGUUspTdw4Q89u7Am1En7Nr0efsWjr0c3bbMQillFJN684tCKWUUk3olgFCRM4VkU0islVEbmnv+hwLEfmbiJSIyNqwst4i8q6IbLG/97LLRUT+bD/3GhE5sf1q3nIiMkREFovIBhFZJyI/tsu72nNmiMhyEVltP+eddvkIEVlmP+dzIpJml6fb51vt68Pbs/5HSkSSReQLEXndPu9yzykiO0XkSxFZJSIr7LJO83vb7QKEiCQDDwHnAROAb4rIhPat1TF5HDg3quwWYKExZjSw0D4H65lH21/XAw+3UR2PVQC42RgzHpgJ3GT/P+tqz9kAnGGMOR6YApwrIjOBe4H77ec8DMyz758HHDbGjALut+/rTH4MbAg776rPeboxZkrYdNbO83trjOlWX8As4O2w81uBW9u7Xsf4TMOBtWHnm4AB9vEAYJN9/AjwTa/7OtMX8Apwdld+TiAL+ByYgbWQKsUud39/gbeBWfZxin2ftHfdW/h8g7E+HM8AXgekiz7nTqBPVFmn+b3tdi0IYBCwJ+y8yC7rSvoZY/YD2N/72uWd/tnt7oUTgGV0wee0u11WASXAu8A2oNwYE7BvCX8W9znt6xVAftvW+Kj9Cfg5ELLP8+maz2mAd0RkpYhcb5d1mt/b7rgntXiUdZepXJ362UWkB/AC8BNjTKWI1+NYt3qUdYrnNMYEgSkikge8BIz3us3+3imfU0QuBEqMMStF5DSn2OPWTv2cttnGmH0i0hd4V0Q2NnFvh3vO7tiCKAKGhJ0PBva1U10SpVhEBgDY30vs8k777CKSihUcnjLGvGgXd7nndBhjyoH3scZc8kTE+WMu/Fnc57Sv5wJlbVvTozIbuEhEdgLPYnUz/Ymu95wYY/bZ30uwAv50OtHvbXcMEJ8Bo+0ZE2nAlcCr7Vyn1vYqcLV9fDVWn71T/h17tsRMoMJp6nZkYjUVHgU2GGPuC7vU1Z6zwG45ICKZwFlYg7iLgcvs26Kf03n+y4BFxu687siMMbcaYwYbY4Zj/ftbZIz5Nl3sOUUkW0RynGPgHGAtnen3tr0HcdrjCzgf2IzVv/ur9q7PMT7LM8B+wI/1F8g8rP7ZhcAW+3tv+17BmsG1DfgSmNre9W/hM87BamqvAVbZX+d3weecDHxhP+da4Ha7vBBYDmwF/gGk2+UZ9vlW+3phez/DUTzzacDrXfE57edZbX+tcz5rOtPvra6kVkop5ak7djEppZRqAQ0QSimlPGmAUEop5UkDhFJKKU8aIJRSSnnSAKG6JREJ2hk2na8ms/qKyI0i8p1W+Lk7RaTPUbzuKyJyh4j0EpE3j7UeSrVEd0y1oRRAnTFmSktvNsb8byIr0wKnYC0kOxVY2s51Ud2EBgilwtjpH54DTreLvmWM2SoidwDVxpg/isiPgBux0pCvN8ZcKSK9gb9hLY6qBa43xqwRkXysxYwFWIu8JOxn/RvwIyANK/ngD4yViym8PldgZRwuBC4G+gGVIjLDGHNRIv4bKOXQLibVXWVGdTFdEXat0hgzHXgQK0dQtFuAE4wxk7ECBcCdwBd22S+BJ+zy3wAfGWNOwEqlMBRARMYDV2Alc5sCBIFvR/8gY8xzwIlY6dwnYa2wPkGDg2oL2oJQ3VVTXUzPhH2/3+P6GuApEXkZeNkumwNcCmCMWSQi+SKSi9Ul9HW7/A0ROWzffyZwEvCZnZU2k8akbdFGY6VfAMgyxlS14PmUOmYaIJSKZeIcOy7A+uC/CLhNRCbSdKpmr/cQYIEx5tamKmJvU9kHSBGR9cAAe7+IHxpjljT9GEodG+1iUirWFWHfPwm/ICJJwBBjzGKsDW/ygB7Ah9hdRPYeBweNMZVR5ecBvey3WghcZu8T4OxTPCy6IsbapvINrPGH32MlfJuiwUG1BW1BqO4q0/5L3PGWMcaZ6pouIsuw/oD6ZtTrkoEn7e4jwdpDudwexH5MRNZgDVI76ZzvBJ4Rkc+BD4DdAMaY9SLya6zdxpKwsvHeBOzyqOuJWIPZPwDu87iuVEJoNlelwtizmKYaYw62d12Uam/axaSUUsqTtiCUUkp50haEUkopTxoglFJKedIAoZRSypMGCKWUUp40QCillPKkAUIppZSn/w+gq15GcxMo6gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "multiagent = MultiAgent(\n",
    "    state_size=state_size, \n",
    "    action_size=action_size,\n",
    "    shared_network_units=[],\n",
    "    actor_network_units=[512, 512, 512],\n",
    "    critic_network_units=[512, 512, 512],\n",
    "    value_loss_weight=1.0,\n",
    "    gradient_clip=0.25,\n",
    "    ppo_ratio_clip_epsilon=0.1,\n",
    "    trajectory_length=1000,\n",
    "    gamma=0.9,\n",
    "    gae_lambda=0.95,\n",
    "    optimization_steps=32,\n",
    "    batch_size=1024,\n",
    "    entropy_penalty_weight=0.01,\n",
    "    optimizer_learning_rate=5e-6,\n",
    "    optimizer_weight_decay=1e-4,\n",
    "    optimizer_epsilon=1e-5,\n",
    "    std_init=-2.5\n",
    ")\n",
    "\n",
    "filename = 'checkpoint-crawler.pth'\n",
    "scores = train_multiagent(\n",
    "    env, \n",
    "    multiagent, \n",
    "    solved_score=400, \n",
    "    display_every=100, \n",
    "    max_t=1000,\n",
    "    n_episodes=2000, \n",
    "    save_filename=filename\n",
    ")\n",
    "multiagent.save(filename)\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 475.12093818101556\n"
     ]
    }
   ],
   "source": [
    "# load the weights from file\n",
    "multiagent.load('checkpoint-crawler.pth')\n",
    "\n",
    "# Run through once with loaded model\n",
    "env_info = env.reset(train_mode=False)[brain_name]            # reset the environment    \n",
    "states = env_info.vector_observations                         # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                                 # initialize the score (for each agent)\n",
    "for t in range(1000):\n",
    "    actions = multiagent.act(states, std_scale=0)             # get actions from model (for each agent)\n",
    "    env_info = env.step(actions)[brain_name]                  # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations                # get next state (for each agent)\n",
    "    rewards = env_info.rewards                                # get reward (for each agent)\n",
    "    dones = env_info.local_done                               # see if episode finished\n",
    "    scores += env_info.rewards                                # update the score (for each agent)\n",
    "    states = next_states                                      # roll over states to next time step\n",
    "    if np.any(dones):                                         # exit loop if episode finished\n",
    "        break\n",
    "\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, we can close the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
